{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D data prep\n",
    "ArcGIS Pro Python script to process LAS and NAIP layers in preparation for 3D analysis and visualization. This script requires that you use this geodatabase containing index layers for downloading assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ArcGIS package\n",
    "import arcpy\n",
    "# Subprocess allows us to issue commands on the command line\n",
    "import subprocess\n",
    "# Module to download files with an URL\n",
    "from urllib.request import urlretrieve\n",
    "# Zip utlity to extract files\n",
    "from zipfile import ZipFile\n",
    "# pandas to view table and possibly analyze data in the future?\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "* Pick a location anywhere in Kentucky and drop a point in ArcGIS.\n",
    "* Download and extract [download_grids.gdb.zip](../pointcloud_extract/download_grids.gdb.zip)\n",
    "\n",
    "## Cumberland Falls example\n",
    "![cufa](../pointcloud_extract/cufa.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for project \n",
    "# Got to use double backslash because of other modules\n",
    "out_directory = \"Z:\\\\BoydsGIS\\\\L7\\\\\"\n",
    "\n",
    "# Project name - creates a folder in project directoru\n",
    "project = \"cfalls\"\n",
    "\n",
    "# Name of point layer and buffer distance from point\n",
    "point_name = \"cumberland_falls\"\n",
    "buffer_distance = 1000\n",
    "\n",
    "# Output geodatabase name\n",
    "out_geodb = \"workspace.gdb\"\n",
    "\n",
    "# Locations of index grids\n",
    "las_grid = \"Z:/BoydsGIS/data/download_grids.gdb/KY_5k_PointClound_grid\"\n",
    "naip_grid = \"Z:/BoydsGIS/data/download_grids.gdb/Kentucky_10K_NAIP\"\n",
    "\n",
    "# NAIP files have prefix\n",
    "naip_prefix = \"ky_2ft_naip_2016_\"\n",
    "\n",
    "# Point the script to the directory with the laszip64.exe\n",
    "las_tools = [\"Z:\\\\BoydsGIS\\\\data\\\\lidar\\\\\", \"laszip64.exe\"]\n",
    "\n",
    "# Downloads folder\n",
    "downloads = f'{out_directory}{project}\\\\downloads\\\\'\n",
    "lidar = f'{out_directory}{project}\\\\lidar\\\\'\n",
    "lidar_color = f'{out_directory}{project}\\\\lidar_color\\\\'\n",
    "\n",
    "# LAS dataset name, temp list, and class codes\n",
    "las_dataset = f'{lidar}{project}.lasd'\n",
    "las_names = []\n",
    "las_ground = [2, 9]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cufa](../pointcloud_extract/cufa.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create folders and copy laszip64.exe\n",
    "subprocess.run(f'mkdir {out_directory}{project}', shell=True)\n",
    "subprocess.run(f'mkdir {out_directory}{project}\\\\downloads', shell=True)\n",
    "subprocess.run(f'mkdir {out_directory}{project}\\\\lidar', shell=True)\n",
    "subprocess.run(f'mkdir {out_directory}{project}\\\\lidar_color', shell=True)\n",
    "completed = subprocess.run(f'dir', shell=True, stdout=subprocess.PIPE)\n",
    "print(completed.stdout.decode('UTF-8'))\n",
    "completed = subprocess.run(f'copy {las_tools[0]}{las_tools[1]} {downloads}', shell=True, stdout=subprocess.PIPE)\n",
    "print(completed.stdout.decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.env.overwriteOutput = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create project geodatabase\n",
    "arcpy.CreateFileGDB_management(f'{out_directory}{project}', out_geodb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create project default geodatabase\n",
    "out_path = f'{out_directory}{project}\\\\{out_geodb}'\n",
    "arcpy.env.workspace = out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty point layer\n",
    "spatial_reference = arcpy.Describe(source_grid).spatialReference\n",
    "arcpy.CreateFeatureclass_management(out_path, point_name, \"POINT\", \"#\", \"#\", \"#\", spatial_reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open ArcGIS Pro\n",
    "\n",
    "What location do you want? Edit the empty point layer by dropping a **single** point somewhere in Kentucky. Save the edit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buffer point\n",
    "arcpy.Buffer_analysis(point_name, f'{point_name}_{buffer_distance}ft', buffer_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temp layer to find which LAS files to download\n",
    "arcpy.Intersect_analysis ([f'{point_name}_{buffer_distance}ft', las_grid], \"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find URLs and download them and use laszip64.exe to convert \n",
    "cursor = arcpy.da.SearchCursor(\"temp\", ['ftppath', 'LASVersion', 'Year'])\n",
    "i = 0\n",
    "las_names = []\n",
    "for row in cursor:\n",
    "    url = row[0]\n",
    "    name = url[-12:]\n",
    "    las_names.append(f'{lidar}{url[-12:-4]}.las')\n",
    "    print(las_names)\n",
    "    urlretrieve(url, f'{downloads}{name}')\n",
    "    completed = subprocess.run(f'{downloads}{las_tools[1]} -i {downloads}{name} -o {lidar}{las_names[i]}', shell=True, stdout=subprocess.PIPE)\n",
    "    print(completed.stdout.decode('UTF-8'))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.CreateLasDataset_management (las_names, las_dataset, \"#\", \"#\", spatial_reference, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.LasDatasetStatistics_management (las_dataset, \"#\", f'{out_directory}{project}\\\\stats.csv', \"#\", \"#\", \"#\")\n",
    "with open(f'{out_directory}{project}\\\\stats.csv', encoding='utf-8') as csv:\n",
    "    reader = pd.read_csv(csv)\n",
    "    # Create pandas data frame that\n",
    "    pdData = pd.DataFrame(reader)\n",
    "\n",
    "pdData[pdData[\"Category\"] == \"ClassCodes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decide which class codes to add/change\n",
    "Use the table above and decide which classes to include. Some parts of the state have more detailed classes. E.g., Louisville has building codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default ground classes\n",
    "las_ground = [2, 9]\n",
    "\n",
    "# Filter for ground points and create DEM and hillshade\n",
    "arcpy.MakeLasDatasetLayer_management (las_dataset, f'{lidar}ground', las_ground)\n",
    "arcpy.LasDatasetToRaster_conversion (f'{lidar}ground', f'{project}_dem_5ft', \"#\", \"#\", \"#\", \"#\", 5)\n",
    "arcpy.HillShade_3d(f'{project}_dem_5ft', f'{project}_hillshade', 270, 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temp layer to find which NAIP files to download\n",
    "arcpy.RasterDomain_3d (f'{project}_hillshade', 'domain', 'POLYGON')\n",
    "arcpy.Intersect_analysis (['domain', naip_grid], \"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find URLs, download them and extract \n",
    "cursor = arcpy.da.SearchCursor(\"temp\", ['ftppath16', 'TileName'])\n",
    "i = 0\n",
    "naip_names = []\n",
    "for row in cursor:\n",
    "    url = row[0]\n",
    "    name = row[1]\n",
    "    naip_names.append(name)\n",
    "    print(naip_names)\n",
    "    urlretrieve(url, f'{downloads}{name}.zip')\n",
    "    with ZipFile(f'{downloads}{name}.zip', 'r') as zip: \n",
    "        zip.extractall(f'{downloads}{name}') \n",
    "    arcpy.CopyRaster_management (f'{downloads}{name}\\\\{naip_prefix}{name}.jpg', name)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If multiple NAIPs, then mosaic to new raster and clip\n",
    "if len(naip_names) > 1:\n",
    "    arcpy.MosaicToNewRaster_management (naip_names, out_path, \"temp\", \"#\", \"#\", \"#\", 3. \"#\", \"#\")\n",
    "    arcpy.Clip_management ('temp', '#', f'{project}_naip', 'domain')\n",
    "else:\n",
    "    arcpy.Clip_management (naip_names[0], '#', f'{project}_naip', 'domain')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract LAS points in buffer and colorize\n",
    "arcpy.ExtractLas_3d (las_dataset, lidar, f'{point_name}_{buffer_distance}ft', \"#\", \"#\", \"_extract\", \"#\", \"#\", True, f'{lidar_local}temp.lasd')\n",
    "arcpy.ColorizeLas_3d (f'{lidar_local}temp.lasd', f'{project}_naip', 'RED Band_1; GREEN Band_2; BLUE Band_3', lidar_color, \"_color\", \"#\",  \"#\",  \"#\",  \"#\", True, f'{lidar_color}{project}_rgb.lasd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DSM of cliffs over 30 feet in 30-ft diameter neighborhood from bare-earth DEM\n",
    "neighborhood = arcpy.sa.NbrCircle(3,'CELL')\n",
    "outFocalStat = arcpy.sa.FocalStatistics(f'{project}_dem_5ft', neighborhood, \"RANGE\")\n",
    "outFocalStat.save(\"focal_stats_30ft\")\n",
    "cliffs_over_30ft = arcpy.sa.Con(outFocalStat > 30, outFocalStat)\n",
    "cliffs_over_30ft.save(\"cliffs_over_30ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
